{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Moving and Sensing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Class\n",
    "\n",
    "In this project, we'll are localizing a robot in a 2D grid world. The basis for simultaneous localization and mapping (SLAM) is to gather information from a robot's sensors and motions over time, and then use information about measurements and motion to re-construct a map of the world.\n",
    "\n",
    "### Uncertainty\n",
    "\n",
    "Robot motion and sensors have some uncertainty associated with them. For example, imagine a car driving up hill and down hill; the speedometer reading will likely overestimate the speed of the car going up hill and underestimate the speed of the car going down hill because it cannot perfectly account for gravity. Similarly, we cannot perfectly predict the *motion* of a robot. A robot is likely to slightly overshoot or undershoot a target location.\n",
    "\n",
    "First, we create a robot and move it around a 2D grid world. Then, define a `sense` function for this robot that allows it to sense landmarks in a given world! \n",
    "\n",
    "---\n",
    "\n",
    "Before we start analyzing robot motion, let's load in our resources and define the `robot` class. This class initializes the robot's position and adds measures of uncertainty for motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some resources\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the robot class\n",
    "class robot:\n",
    "\n",
    "    # --------\n",
    "    # init: \n",
    "    #   creates a robot with the specified parameters and initializes \n",
    "    #   the location (self.x, self.y) to the center of the world\n",
    "    #\n",
    "    def __init__(self, world_size = 100.0, measurement_range = 30.0,\n",
    "                 motion_noise = 1.0, measurement_noise = 1.0):\n",
    "        self.measurement_noise = 0.0\n",
    "        self.world_size = world_size\n",
    "        self.measurement_range = measurement_range\n",
    "        self.x = world_size / 2.0\n",
    "        self.y = world_size / 2.0\n",
    "        self.motion_noise = motion_noise\n",
    "        self.measurement_noise = measurement_noise\n",
    "        self.landmarks = []\n",
    "        self.num_landmarks = 0\n",
    "\n",
    "\n",
    "    # returns a positive, random float\n",
    "    def rand(self):\n",
    "        return random.random() * 2.0 - 1.0\n",
    "\n",
    "\n",
    "    # --------\n",
    "    # move: attempts to move robot by dx, dy. If outside world\n",
    "    #       boundary, then the move does nothing and instead returns failure\n",
    "    #\n",
    "    def move(self, dx, dy):\n",
    "\n",
    "        x = self.x + dx + self.rand() * self.motion_noise\n",
    "        y = self.y + dy + self.rand() * self.motion_noise\n",
    "\n",
    "        if x < 0.0 or x > self.world_size or y < 0.0 or y > self.world_size:\n",
    "            return False\n",
    "        else:\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "            return True\n",
    "    \n",
    "\n",
    "    # --------\n",
    "    # sense: returns x- and y- distances to landmarks within visibility range\n",
    "    #        because not all landmarks may be in this range, the list of measurements\n",
    "    #        is of variable length. Set measurement_range to -1 if you want all\n",
    "    #        landmarks to be visible at all times\n",
    "    #\n",
    "    \n",
    "    ## TODO: complete the sense function\n",
    "    def sense(self):\n",
    "        ''' This function does not take in any parameters, instead it references internal variables\n",
    "            (such as self.landamrks) to measure the distance between the robot and any landmarks\n",
    "            that the robot can see (that are within its measurement range).\n",
    "            This function returns a list of landmark indices, and the measured distances (dx, dy)\n",
    "            between the robot's position and said landmarks.\n",
    "            This function should account for measurement_noise and measurement_range.\n",
    "            One item in the returned list should be in the form: [landmark_index, dx, dy].\n",
    "            '''\n",
    "           \n",
    "        measurements = []\n",
    "        \n",
    "        ## iterate through all of the landmarks in a world\n",
    "        \n",
    "        ## For each landmark\n",
    "        ## 1. compute dx and dy, the distances between the robot and the landmark\n",
    "        ## 2. account for measurement noise by *adding* a noise component to dx and dy\n",
    "        ##    - The noise component should be a random value between [-1.0, 1.0)*measurement_noise\n",
    "        ##    - Feel free to use the function self.rand() to help calculate this noise component\n",
    "        ##    - It may help to reference the `move` function for noise calculation\n",
    "        ## 3. If either of the distances, dx or dy, fall outside of the internal var, measurement_range\n",
    "        ##    then we cannot record them; if they do fall in the range, then add them to the measurements list\n",
    "        ##    as list.append([index, dx, dy]), this format is important for data creation done later\n",
    "        \n",
    "        ## TODO: return the final, complete list of measurements\n",
    "        for landmark in self.landmarks:\n",
    "            \n",
    "            dx = landmark[0] - self.x + self.measurement_noise * self.rand()\n",
    "            dy = landmark[1] - self.y + self.measurement_noise * self.rand()\n",
    "            \n",
    "            if abs(dx)< self.measurement_range and abs(dy) < self.measurement_range:\n",
    "                measurements.append([self.landmarks.index(landmark), dx, dy])\n",
    "                \n",
    "        return measurements\n",
    "\n",
    "    \n",
    "    # --------\n",
    "    # make_landmarks: \n",
    "    # make random landmarks located in the world\n",
    "    #\n",
    "    def make_landmarks(self, num_landmarks):\n",
    "        self.landmarks = []\n",
    "        for i in range(num_landmarks):\n",
    "            self.landmarks.append([round(random.random() * self.world_size),\n",
    "                                   round(random.random() * self.world_size)])\n",
    "        self.num_landmarks = num_landmarks\n",
    "    \n",
    "    \n",
    "    # called when print(robot) is called; prints the robot's location\n",
    "    def __repr__(self):\n",
    "        return 'Robot: [x=%.5f y=%.5f]'  % (self.x, self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a world and a robot\n",
    "\n",
    "Next, let's instantiate a robot object. The robot class takes in a number of parameters including a world size and some values that indicate the sensing and movement capabilities of the robot.\n",
    "\n",
    "Next , we define a small 10x10 square world, a measurement range that is half that of the world and small values for motion and measurement noise. These values will typically be about 10 times larger, but we want to demonstrate this behavior on a small scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot: [x=5.00000 y=5.00000]\n"
     ]
    }
   ],
   "source": [
    "world_size         = 10.0    # size of world (square)\n",
    "measurement_range  = 5.0     # range at which we can sense landmarks\n",
    "motion_noise       = 0.2      # noise in robot motion\n",
    "measurement_noise  = 0.2      # noise in the measurements\n",
    "\n",
    "# instantiate a robot, r\n",
    "r = robot(world_size, measurement_range, motion_noise, measurement_noise)\n",
    "\n",
    "# print out the location of r\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the World\n",
    "\n",
    "In the given example, we can see/print out that the robot is in the middle of the 10x10 world at (x, y) = (5.0, 5.0), which is exactly what we expect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot: [x=5.00000 y=5.00000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import helper function\n",
    "from helpers import display_world\n",
    "\n",
    "# define figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "\n",
    "# call display_world and display the robot in it's grid world\n",
    "print(r)\n",
    "display_world(int(world_size), [r.x, r.y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movement\n",
    "\n",
    "Now you can really picture where the robot is in the world! Next, let's call the robot's `move` function. We'll ask it to move some distance `(dx, dy)` and we'll see that this motion is not perfect by the placement of our robot `o` and by the printed out position of `r`. \n",
    "\n",
    "Try changing the values of `dx` and `dy` and/or running this cell multiple times; see how the robot moves and how the uncertainty in robot motion accumulates over multiple movements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot: [x=5.86805 y=7.07235]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEzCAYAAABHZATQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ4ElEQVR4nO3df2zV9X7H8dehpUBp4e7gt+0IxIQiuwxM/5FhLz8cZZQikBZoRO50rsRbYhaPrqADOvTGXWTLgHlZ9ocNI1AXNwKYdqHGEAqIEVBEAtuKLg5N4F5omw5KKbS0x+/+8LbK/FH49vv9Hvy+n49/gOP5ns/7k5Cn33NOv3xjruu6AgBjhqR6AABIBeIHwCTiB8Ak4gfAJOIHwCTiB8CkAeO3bt06FRYWatGiRf2PXb16VRUVFSouLlZFRYXa29sDHRIA/DZg/JYuXart27ff9lhNTY0KCwt14MABFRYWqqamJrABASAIA8Zv2rRpGj169G2PNTY2qqysTJJUVlamgwcPBjIcAATF02d+bW1tysnJkSQ5jqO2tjZfhwKAoA36C49YLKZYLObHLAAQmnQvB40ZM0YtLS3KyclRS0uL4vH4HR/b2trhZUlPHCc7tPUcJ1tSNPcX5b31rSWxP7/XDHt/d8vTmV9RUZHq6uokSXV1dZo7d66nxQEgVQaMX1VVlR5//HF9/vnnmj17tvbs2aPKykq9//77Ki4u1rFjx1RZWRnGrADgmwHf9m7duvU7H9+1a5fvwwBAWLjCA4BJxA+AScQPgEnED4BJxA+AScQPgEnED4BJxA+AScQPgEnED4BJxA+AScQPgEnED4BJxA+AScQPgEnED4BJxA+AScQPgEnED4BJxA+AScQPgEnED4BJMdd13VQPAQBhG/C+vX5rbe0IbS3HyQ5tPcfJlhTN/UV5b31rSezP7zXD3t/d4m0vAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJMGdevKnTt3as+ePYrFYpo0aZI2bdqkYcOG+TUbAATG85lfc3OzamtrtW/fPu3fv1/JZFINDQ1+zgYAgRnUmV8ymVRXV5fS09PV1dWlnJycAY/xeoNhr1jvx7kW67Fe0DzHLzc3VytXrtScOXM0bNgwzZgxQzNnzvRzNgAIjOf4tbe3q7GxUY2NjcrOztZzzz2n+vp6lZaW/uBxra0dXpe8a46THdp6ff+Xi+L+ory3vrUk9uf3mmHv7255/szv2LFjGjdunOLxuIYOHari4mKdPn3a68sBQKg8x2/s2LE6c+aMbt68Kdd1dfz4ceXn5/s5GwAExvPb3oKCAs2fP19LlixRenq6Jk+erOXLl/s5GwAEZlDf9iYSCSUSCb9mAYDQcIUHAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTBnVtL/Bjkvbfn2r4rn9WxnvvashvfqNYzy19eZ8jFT4srVghzfyTVI+IEBE/mJD5dxuV+dpmxZLJ2x5Pu3hB2nNB2rNHo2fM0rUdb8j9vXiKpkSYiB8ib+SvfqnMbVslSW5amrrLlqln1iNyhw9X+rkmZf7bv0jNzcp4/z39ZMkiXXnnkDR8eIqnRtCIHyIt/eQHGvGP/yBJcjNHqv1f96qncEb/f++WlPnSemn+fOmjj5Te9J8a+be/Uucvf5WiiREWvvBApGX+0zbFXFeSdP3lv7ktfP3icWnvXrmZmZKk4bt2KNZ+NcQpkQrED9HV3a2MxgOSpC/jcXX96Z99/3Pvv19dS8olSUM6ryvjyKEwJkQKET9EVvp//Ydi3d2SpJ6fzZIyMn7w+T1/XPT1sac+CnQ2pB7xQ2QNaW7u/30yf+KAz++d8PVzhrRcDmQm3DuIHyIrdv3r+8b2fZ73Q9yRI79x7PVAZsK9g/ghstysr29mHbtxY8Dnxzo7v3FsViAz4d5B/BBZX+bm9v8+7fz/DPj8tM+/fs6Xub8fyEy4d8Rc93c/BwBETXe3NHr0V7/ed5/0299KQ4d+//N/8Qtp+/avfr97t/TYY+HMiZQIPX6trR0DP8knjpMd2nqO89VbrCju78e8t1EVT2hYw79Lkjq2bFPXk3/+nWvpwgW5P52s2I1OfTkyS/975pzcUaMHvf734e+mv2t5wdteRNqNv0jIHfLVX/ORL1cr/YMT337SlStSebliN776zK/rqZWBhg/3Bi5vQ6T1PvRHuvnsXyrz11s05HqHflK2QN1LynVr1iPS8OFK+6RJevMN6Xc/FtP7h1PV+VfVKZ4aYSB+iLzO6pflpqUp89dbFEsmNXzvbg3fu/tbz7v1s5m6tuMNacSIFEyJsBE/mHBj7V+re0n5t/89vzH3Ka3wYennP1f7rHmpHhMhIn4wI/kHP1Xnq3+vzv/3eP8H5iF+IYDU4wsPACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYNKn7Xrl1TIpFQSUmJFixYoNOnT/s1FwAEalD/kvPGjRs1a9Ysbdu2Tbdu3VJXV5dfcwFAoDyf+XV0dOjkyZMqLy+XJGVkZGjUqFG+DQYAQfJ80/Jz585pw4YNmjhxoj755BNNmTJF1dXVyszM9HtGAPCd5zO/3t5eNTU1acWKFaqrq9OIESNUU1Pj52wAEBjPn/nl5eUpLy9PBQUFkqSSkpI7il9riHfIcpzs0NbruwNYFPcX5b31rSWxP7/XDHt/d8vzmZ/jOMrLy9P58+clScePH1d+fr7XlwOAUA3q294NGzZozZo16unp0fjx47Vp0ya/5gKAQA0qfpMnT9Zbb73l1ywAEBqu8ABgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgUsx1XTfVQwBA2AZ1314vWls7QlvLcbJDW89xsiVFc39R3lvfWhL783vNsPd3t3jbC8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwKRBxy+ZTKqsrEyrVq3yYx4ACMWg41dbW6v8/Hw/ZgGA0AwqfpcvX9aRI0dUXl7u1zwAEIqY67qu14MTiYQqKyvV2dmpHTt26PXXX/dzNgAIjOczv8OHDysej2vq1Kl+zgMAofB85rdlyxbV19crPT1d3d3dun79uubNm6fNmzf/4HGtrR2eBvXCcbJDW89xsiVFc39R3lvfWhL783vNsPd3t9K9Lrh69WqtXr1akvTBBx9ox44dA4YPAO4V/JwfAJM8n/l90/Tp0zV9+nQ/XgoAQsGZHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTYq7ruqkeAgDC5st9e+9Ga2tHaGs5TnZo6zlOtqRo7i/Ke+tbS2J/fq8Z9v7uFm97AZhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJhE/ACYRPwAmET8AJjk+daVly5d0osvvqi2tjbFYjE99thjeuqpp/ycDQAC4zl+aWlpWrt2raZMmaLr169r2bJlmjFjhiZOnOjnfAAQiJjruq4fL/TMM8/oiSee0IwZM/x4OQAIlC+f+V28eFHnzp1TQUGBHy8HAIHz/La3T2dnpxKJhNavX6+srKwBn9/a2jHYJe+Y42SHtp7jZEuK5v6ivLe+tST25/eaYe/vbg3qzK+np0eJREKLFy9WcXHxYF4KAELlOX6u66q6uloTJkxQRUWFnzMBQOA8x+/UqVOqr6/XiRMnVFpaqtLSUr377rt+zgYAgfH8md9DDz2kTz/91M9ZACA0XOEBwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwCTiB8Ak4gfAJOIHwKSY67puqocAgLB5vm+vV62tHaGt5TjZoa3nONmSorm/KO+tby2J/fm9Ztj7u1u87QVgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2AS8QNgEvEDYBLxA2DSoOJ39OhRzZ8/X/PmzVNNTY1fMwFA4DzHL5lM6pVXXtH27dvV0NCg/fv367PPPvNzNgAIjOf4nT17Vvfff7/Gjx+vjIwMLVy4UI2NjX7OBgCB8XzT8ubmZuXl5fX/OTc3V2fPnh3wOK83GPaK9X6ca7Ee6wWNLzwAmOQ5frm5ubp8+XL/n5ubm5Wbm+vLUAAQNM/xe/DBB/XFF1/owoULunXrlhoaGlRUVOTnbAAQGM+f+aWnp+ull17S008/rWQyqWXLlumBBx7wczYACEzMdV031UMAQNj4wgOAScQPgEmhxC/Kl8FdunRJTz75pB599FEtXLhQu3btSvVIgUgmkyorK9OqVatSPYrvrl27pkQioZKSEi1YsECnT59O9Ui+2rlzpxYuXKhFixapqqpK3d3dqR5pUNatW6fCwkItWrSo/7GrV6+qoqJCxcXFqqioUHt7+4CvE3j8on4ZXFpamtauXau3335bu3fv1ptvvhmp/fWpra1Vfn5+qscIxMaNGzVr1iy98847qq+vj9Q+m5ubVVtbq3379mn//v1KJpNqaGhI9ViDsnTpUm3fvv22x2pqalRYWKgDBw6osLDwjk6yAo9f1C+Dy8nJ0ZQpUyRJWVlZmjBhgpqbm1M8lb8uX76sI0eOqLy8PNWj+K6jo0MnT57s31tGRoZGjRqV4qn8lUwm1dXVpd7eXnV1dSknJyfVIw3KtGnTNHr06Nsea2xsVFlZmSSprKxMBw8eHPB1Ao/fd10GF7U49Ll48aLOnTungoKCVI/iq1dffVUvvPCChgyJ3kfEFy9eVDwe17p161RWVqbq6mrduHEj1WP5Jjc3VytXrtScOXM0c+ZMZWVlaebMmakey3dtbW39UXccR21tbQMeE72/zSnS2dmpRCKh9evXKysrK9Xj+Obw4cOKx+OaOnVqqkcJRG9vr5qamrRixQrV1dVpxIgRkfpcur29XY2NjWpsbNR7772nmzdvqr6+PtVjBSoWiykWiw34vMDjZ+EyuJ6eHiUSCS1evFjFxcWpHsdXH3/8sQ4dOqSioiJVVVXpxIkTWrNmTarH8k1eXp7y8vL6z9ZLSkrU1NSU4qn8c+zYMY0bN07xeFxDhw5VcXFx5L7QkaQxY8aopaVFktTS0qJ4PD7gMYHHL+qXwbmuq+rqak2YMEEVFRWpHsd3q1ev1tGjR3Xo0CFt3bpVDz/8sDZv3pzqsXzjOI7y8vJ0/vx5SdLx48cj9YXH2LFjdebMGd28eVOu60Zuf32KiopUV1cnSaqrq9PcuXMHPMbz5W13KuqXwZ06dUr19fWaNGmSSktLJUlVVVV65JFHUjwZ7tSGDRu0Zs0a9fT0aPz48dq0aVOqR/JNQUGB5s+fryVLlig9PV2TJ0/W8uXLUz3WoFRVVenDDz/UlStXNHv2bD377LOqrKzU888/r71792rs2LF67bXXBnwdLm8DYBJfeAAwifgBMIn4ATCJ+AEwifgBMIn4ATCJ+AEwifgBMOn/AC0C6oWAtSa8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose values of dx and dy (negative works, too)\n",
    "dx = 1\n",
    "dy = 2\n",
    "r.move(dx, dy)\n",
    "\n",
    "# print out the exact location\n",
    "print(r)\n",
    "\n",
    "# display the world after movement, not that this is the same call as before\n",
    "# the robot tracks its own movement\n",
    "display_world(int(world_size), [r.x, r.y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landmarks\n",
    "\n",
    "Next, let's create landmarks, which are measurable features in the map. You can think of landmarks as things like notable buildings, or something smaller such as a tree, rock, or other feature.\n",
    "\n",
    "The robot class has a function `make_landmarks` which randomly generates locations for the number of specified landmarks. Try changing `num_landmarks` or running this cell multiple times to see where these landmarks appear. We have to pass these locations as a third argument to the `display_world` function and the list of landmark locations is accessed similar to how we find the robot position `r.landmarks`. \n",
    "\n",
    "Each landmark is displayed as a purple `x` in the grid world, and we also print out the exact `[x, y]` locations of these landmarks at the end of this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot: [x=5.86805 y=7.07235]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark locations [x,y]:  [[8, 3], [8, 8], [8, 10]]\n"
     ]
    }
   ],
   "source": [
    "# create any number of landmarks\n",
    "num_landmarks = 3\n",
    "r.make_landmarks(num_landmarks)\n",
    "\n",
    "# print out our robot's exact location\n",
    "print(r)\n",
    "\n",
    "# display the world including these landmarks\n",
    "display_world(int(world_size), [r.x, r.y], r.landmarks)\n",
    "\n",
    "# print the locations of the landmarks\n",
    "print('Landmark locations [x,y]: ', r.landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sense\n",
    "\n",
    "Once we have some landmarks to sense, we need to be able to tell our robot to *try* to sense how far they are away from it.\n",
    "\n",
    "The `sense` function uses only internal class parameters and returns a list of the the measured/sensed x and y distances to the landmarks it senses within the specified `measurement_range`. \n",
    "\n",
    "The measurements have the format, `[i, dx, dy]` where `i` is the landmark index (0, 1, 2, ...) and `dx` and `dy` are the measured distance between the robot's location (x, y) and the landmark's location (x, y). This distance will not be perfect since our sense function has some associated `measurement noise`.\n",
    "\n",
    "---\n",
    "\n",
    "In the example in the following cell, we have a given our robot a range of `5.0` so any landmarks that are within that range of our robot's location, should appear in a list of measurements. Not all landmarks are guaranteed to be in our visibility range, so this list will be variable in length.\n",
    "\n",
    "*Note: the robot's location is often called the **pose** or `[Pxi, Pyi]` and the landmark locations are often written as `[Lxi, Lyi]`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2.3009052290344223, -3.8786957878339625], [1, 2.0237275762299327, 0.9697753489277304], [2, 2.22792308925932, 2.916185220906598]]\n"
     ]
    }
   ],
   "source": [
    "# try to sense any surrounding landmarks\n",
    "measurements = r.sense()\n",
    "\n",
    "# this will print out an empty list if `sense` has not been implemented\n",
    "print(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "#### Putting it all together\n",
    "\n",
    "To perform SLAM, we'll collect a series of robot sensor measurements and motions, in that order, over a defined period of time. Then we'll use only this data to re-construct the map of the world with the robot and landmark locations. You can think of SLAM as peforming what we've done in this notebook, only backwards. Instead of defining a world and robot and creating movement and sensor data, it will be up to you to use movement and sensor measurements to reconstruct the world!\n",
    "\n",
    "Next we see this list of movements and measurements (used to re-construct the world) listed in a structure called `data`. This is an array that holds sensor measurements and movements in a specific order, which will be useful to call upon when you have to extract this data and form constraint matrices and vectors.\n",
    "\n",
    "`data` is constructed over a series of time steps as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0, 2.3009052290344223, -3.8786957878339625], [1, 2.0237275762299327, 0.9697753489277304], [2, 2.22792308925932, 2.916185220906598]], [1, 2]]]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "# after a robot first senses, then moves (one time step)\n",
    "# that data is appended like so:\n",
    "data.append([measurements, [dx, dy]])\n",
    "\n",
    "# for our example movement and measurement\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements:  [[0, 2.3009052290344223, -3.8786957878339625], [1, 2.0237275762299327, 0.9697753489277304], [2, 2.22792308925932, 2.916185220906598]]\n",
      "Motion:  [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# in this example, we have only created one time step (0)\n",
    "time_step = 0\n",
    "\n",
    "# so you can access robot measurements:\n",
    "print('Measurements: ', data[time_step][0])\n",
    "\n",
    "# and its motion for a given time step:\n",
    "print('Motion: ', data[time_step][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omega and Xi, Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omega and Xi\n",
    "\n",
    "To implement Graph SLAM, a matrix and a vector (omega and xi, respectively) are introduced. The matrix is square and labelled with all the robot poses (xi) and all the landmarks (Li). Every time you make an observation, for example, as you move between two poses by some distance `dx` and can relate those two positions, you can represent this as a numerical relationship in these matrices.\n",
    "\n",
    "It's easiest to see how these work in an example. Below you can see a matrix representation of omega and a vector representation of xi.\n",
    "\n",
    "<img src='images/omega_xi.png' width=20% height=20% />\n",
    "\n",
    "Next, let's look at a simple example that relates 3 poses to one another. \n",
    "* When you start out in the world most of these values are zeros or contain only values from the initial robot position\n",
    "* In this example, you have been given constraints, which relate these poses to one another\n",
    "* Constraints translate into matrix values\n",
    "\n",
    "<img src='images/omega_xi_constraints.png' width=70% height=70% />\n",
    "\n",
    "If you have ever solved linear systems of equations before, this may look familiar, and if not, let's keep going!\n",
    "\n",
    "### Solving for x\n",
    "\n",
    "To \"solve\" for all these x values, we can use linear algebra; all the values of x are in the vector `mu` which can be calculated as a product of the inverse of omega times xi.\n",
    "\n",
    "<img src='images/solution.png' width=30% height=30% />\n",
    "\n",
    "---\n",
    "**You can confirm this result for yourself by executing the math in the cell below.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define omega and xi as in the example\n",
    "omega = np.array([[1,0,0],\n",
    "                  [-1,1,0],\n",
    "                  [0,-1,1]])\n",
    "\n",
    "xi = np.array([[-3],\n",
    "               [5],\n",
    "               [3]])\n",
    "\n",
    "# calculate the inverse of omega\n",
    "omega_inv = np.linalg.inv(np.matrix(omega))\n",
    "\n",
    "# calculate the solution, mu\n",
    "mu = omega_inv*xi\n",
    "\n",
    "# print out the values of mu (x0, x1, x2)\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Constraints and Landmarks\n",
    "\n",
    "In the last example, the constraint equations, relating one pose to another were given to you. In this next example, let's look at how motion (and similarly, sensor measurements) can be used to create constraints and fill up the constraint matrices, omega and xi. Let's start with empty/zero matrices.\n",
    "\n",
    "<img src='images/initial_constraints.png' width=35% height=35% />\n",
    "\n",
    "This example also includes relationships between poses and landmarks. Say we move from x0 to x1 with a displacement `dx` of 5. Then we have created a motion constraint that relates x0 to x1, and we can start to fill up these matrices.\n",
    "\n",
    "<img src='images/motion_constraint.png' width=50% height=50% />\n",
    "\n",
    "In fact, the one constraint equation can be written in two ways. So, the motion constraint that relates x0 and x1 by the motion of 5 has affected the matrix, adding values for *all* elements that correspond to x0 and x1.\n",
    "\n",
    "### 2D case\n",
    "\n",
    "In these examples, we've been showing you change in only one dimension, the x-dimension. In the project, it will be up to you to represent x and y positional values in omega and xi. One solution could be to create an omega and xi that are 2x larger, so that they can hold both x and y values for poses. I might suggest drawing out a rough solution to graph slam as you read the instructions in the next notebook; that always helps me organize my thoughts. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement SLAM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Overview\n",
    "\n",
    "SLAM gives us a way to both localize a robot and build up a map of its environment as a robot moves and senses in real-time. This is an active area of research in the fields of robotics and autonomous systems. Since this localization and map-building relies on the visual sensing of landmarks, this is a computer vision problem. \n",
    "\n",
    "Using robot motion, representations of uncertainty in motion and sensing, and localization techniques, we define a function, `slam`, which takes in six parameters as input and returns the vector `mu`. \n",
    "> `mu` contains the (x,y) coordinate locations of the robot as it moves, and the positions of landmarks that it senses in the world\n",
    "\n",
    "The vector, `mu`, should have (x, y) coordinates interlaced, for example, if there were 2 poses and 2 landmarks, `mu` will look like the following, where `P` is the robot position and `L` the landmark position:\n",
    "```\n",
    "mu =  matrix([[Px0],\n",
    "              [Py0],\n",
    "              [Px1],\n",
    "              [Py1],\n",
    "              [Lx0],\n",
    "              [Ly0],\n",
    "              [Lx1],\n",
    "              [Ly1]])\n",
    "```\n",
    "\n",
    "\n",
    "## Generating an environment\n",
    "\n",
    "In a real SLAM problem, you may be given a map that contains information about landmark locations, in this example, we will make our own data using the `make_data` function, which generates a world grid with landmarks in it and then generates data by placing a robot in that world and moving and sensing over some numer of time steps. The data is collected as an instantiated robot moves and senses in a world. The SLAM function will take in this data as input. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the world\n",
    "\n",
    "Use the code below to generate a world of a specified size with randomly generated landmark locations. You can change these parameters and see how your implementation of SLAM responds! \n",
    "\n",
    "`data` holds the sensors measurements and motion of your robot over time. It stores the measurements as `data[i][0]` and the motion as `data[i][1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f1816f933b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# make_data instantiates a robot, AND generates random landmarks for a given world size and number of landmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotion_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/vinc3/Projects/slam/helpers.py\u001b[0m in \u001b[0;36mmake_data\u001b[0;34m(N, num_landmarks, world_size, measurement_range, motion_noise, measurement_noise, distance)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotion_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_landmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_landmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# guess an initial motion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from helpers import make_data\n",
    "\n",
    "# world parameters\n",
    "num_landmarks      = 5        # number of landmarks\n",
    "N                  = 20       # time steps\n",
    "world_size         = 100.0    # size of world (square)\n",
    "\n",
    "# robot parameters\n",
    "measurement_range  = 50.0     # range at which we can sense landmarks\n",
    "motion_noise       = 2.0      # noise in robot motion\n",
    "measurement_noise  = 2.0      # noise in the measurements\n",
    "distance           = 20.0     # distance by which robot (intends to) move each iteratation \n",
    "\n",
    "\n",
    "# make_data instantiates a robot, AND generates random landmarks for a given world size and number of landmarks\n",
    "data = make_data(N, num_landmarks, world_size, measurement_range, motion_noise, measurement_noise, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on `make_data`\n",
    "\n",
    "The function above, `make_data`, takes in so many world and robot motion/sensor parameters because it is responsible for:\n",
    "1. Instantiating a robot (using the robot class)\n",
    "2. Creating a grid world with landmarks in it\n",
    "\n",
    "**This function also prints out the true location of landmarks and the *final* robot location, to refer back to when testing the SLAM implementation.**\n",
    "\n",
    "The `data` this returns is an array that holds information about **robot sensor measurements** and **robot motion** `(dx, dy)` that is collected over a number of time steps, `N`.\n",
    "\n",
    "\n",
    "In `data` the measurement and motion data can be accessed from the first and second index in the columns of the data array. See the following code for an example, where `i` is the time step:\n",
    "```\n",
    "measurement = data[i][0]\n",
    "motion = data[i][1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out some stats about the data\n",
    "time_step = 0\n",
    "\n",
    "print('Example measurements: \\n', data[time_step][0])\n",
    "print('\\n')\n",
    "print('Example motion: \\n', data[time_step][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Constraints\n",
    "\n",
    "One of the most challenging tasks here will be to create and modify the constraint matrix and vector: omega and xi. \n",
    "\n",
    "<img src='images/motion_constraint.png' width=50% height=50% />\n",
    "\n",
    "\n",
    "We are referring to robot poses as `Px, Py` and landmark positions as `Lx, Ly`, and one way to approach this challenge is to add *both* x and y locations in the constraint matrices.\n",
    "\n",
    "<img src='images/constraints2D.png' width=50% height=50% />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `initialize_constraints` returns `omega` and `xi` constraints for the starting position of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_constraints(N, num_landmarks, world_size):\n",
    "    ''' This function takes in a number of time steps N, number of landmarks, and a world_size,\n",
    "        and returns initialized constraint matrices, omega and xi.'''\n",
    "    \n",
    "    ## Recommended: Define and store the size (rows/cols) of the constraint matrix in a variable\n",
    "    \n",
    "    ## TODO: Define the constraint matrix, Omega, with two initial \"strength\" values\n",
    "    ## for the initial x, y location of our robot\n",
    "    rows = (N + int(num_landmarks))*2\n",
    "    columns = (N +  int(num_landmarks))*2\n",
    "    world_center = world_size / 2\n",
    "    \n",
    "    omega = np.zeros((rows, columns))\n",
    "    omega[0, 0] = 1\n",
    "    omega[1, 1] = 1\n",
    "    \n",
    "    ## TODO: Define the constraint *vector*, xi\n",
    "    ## you can assume that the robot starts out in the middle of the world with 100% confidence\n",
    "    xi = np.zeros((columns,1))\n",
    "    xi[0] = world_center\n",
    "    xi[1] = world_center\n",
    "    \n",
    "    return omega, xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test as you go\n",
    "\n",
    "It's good practice to test out your code, as you go. Since `slam` relies on creating and updating constraint matrices, `omega` and `xi` to account for robot sensor measurements and motion, let's check that they initialize as expected for any given parameters.\n",
    "\n",
    "Below, you'll find some test code that allows you to visualize the results of your function `initialize_constraints`. We are using the [seaborn](https://seaborn.pydata.org/) library for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data viz resources\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a small N and world_size (small for ease of visualization)\n",
    "N_test = 5\n",
    "num_landmarks_test = 2\n",
    "small_world = 10\n",
    "\n",
    "# initialize the constraints\n",
    "initial_omega, initial_xi = initialize_constraints(N_test, num_landmarks_test, small_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "\n",
    "# display omega\n",
    "sns.heatmap(DataFrame(initial_omega), cmap='Blues', annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define  figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (1,7)\n",
    "\n",
    "# display xi\n",
    "sns.heatmap(DataFrame(initial_xi), cmap='Oranges', annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SLAM inputs \n",
    "\n",
    "In addition to `data`, the slam function will also take in:\n",
    "* N -   The number of time steps that a robot will be moving and sensing\n",
    "* num_landmarks - The number of landmarks in the world\n",
    "* world_size - The size (w/h) of your world\n",
    "* motion_noise - The noise associated with motion; the update confidence for motion should be `1.0/motion_noise`\n",
    "* measurement_noise - The noise associated with measurement/sensing; the update weight for measurement should be `1.0/measurement_noise`\n",
    "\n",
    "#### A note on noise\n",
    "\n",
    "Recall that `omega` holds the relative \"strengths\" or weights for each position variable, and you can update these weights by accessing the correct index in omega `omega[row][col]` and *adding/subtracting* `1.0/noise` where `noise` is measurement or motion noise. `Xi` holds actual position values, and so to update `xi` you'll do a similar addition process only using the actual value of a motion or measurement. So for a vector index `xi[row][0]` you will end up adding/subtracting one measurement or motion divided by their respective `noise`.\n",
    "\n",
    "\n",
    "#### Updating with motion and measurements\n",
    "\n",
    "With a 2D omega and xi structure as shown above (in earlier cells), we have to be mindful about how we update the values in these constraint matrices to account for motion and measurement constraints in the x and y directions. Recall that the solution to these matrices (which holds all values for robot poses `P` and landmark locations `L`) is the vector, `mu`, which can be computed at the end of the construction of omega and xi as the inverse of omega times xi: $\\mu = \\Omega^{-1}\\xi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_matrix(omega, xi, idx, idy, idx_i, idy_i, value_x, value_y, noise):\n",
    "    inv_noise=1/noise\n",
    "    \n",
    "    xi[idx]+= value_x * inv_noise\n",
    "    xi[idx_i]-= value_x * inv_noise\n",
    "    \n",
    "    xi[idy]+= value_y * inv_noise\n",
    "    xi[idy_i]-= value_y * inv_noise\n",
    "    \n",
    "    omega[idx, idx] -= inv_noise\n",
    "    omega[idx, idx_i] += inv_noise\n",
    "    omega[idx_i, idx] += inv_noise\n",
    "    omega[idx_i, idx_i] -= inv_noise\n",
    "    \n",
    "    omega[idy, idy] -= inv_noise\n",
    "    omega[idy, idy_i] += inv_noise\n",
    "    omega[idy_i, idy] += inv_noise\n",
    "    omega[idy_i, idy_i] -= inv_noise\n",
    "    return omega, xi\n",
    "\n",
    "## slam takes in 6 arguments and returns mu, \n",
    "## mu is the entire path traversed by a robot (all x,y poses) *and* all landmarks locations\n",
    "def slam(data, N, num_landmarks, world_size, motion_noise, measurement_noise):\n",
    "    omega, xi = initialize_constraints(N, num_landmarks, world_size)\n",
    "    for i in range(len(data)):\n",
    "        measurement = data[i][0]\n",
    "        motion = data[i][1]\n",
    "        '''\n",
    "        In Omega and Xi, we are storing x and y element as a consecutive elements \n",
    "        like x0, y0, x1, y1 ...., Lxn, Lyn and so on so we need to access it in that \n",
    "        way only, inorder to do measurement and motion update\n",
    "        '''\n",
    "        idx = i * 2\n",
    "        idy = idx + 1\n",
    "        for ind, mesu_x, mesu_y in measurement:\n",
    "            # landmark index starts after 2*N in omega/xi  \n",
    "            idx_1 = (N + ind)*2\n",
    "            idy_1 = idx_1 + 1\n",
    "            omega, xi=update_matrix(omega, xi, idx, idy, idx_1, idy_1, mesu_x, mesu_y, measurement_noise)\n",
    "            \n",
    "        mot_x, mot_y = motion\n",
    "        idx_2 = (i + 1) * 2\n",
    "        idy_2 = idx_2 + 1\n",
    "        omega, xi=update_matrix(omega, xi, idx, idy, idx_2, idy_2, mot_x, mot_y, motion_noise)\n",
    "    omega_inv = np.linalg.inv(omega)\n",
    "    mu = np.dot(omega_inv, xi)\n",
    "    \n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_poses_landmarks(mu, N):\n",
    "    # create a list of poses\n",
    "    poses = []\n",
    "    for i in range(N):\n",
    "        poses.append((mu[2*i].item(), mu[2*i+1].item()))\n",
    "\n",
    "    # create a list of landmarks\n",
    "    landmarks = []\n",
    "    for i in range(num_landmarks):\n",
    "        landmarks.append((mu[2*(N+i)].item(), mu[2*(N+i)+1].item()))\n",
    "\n",
    "    # return completed lists\n",
    "    return poses, landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_all(poses, landmarks):\n",
    "    print('\\n')\n",
    "    print('Estimated Poses:')\n",
    "    for i in range(len(poses)):\n",
    "        print('['+', '.join('%.3f'%p for p in poses[i])+']')\n",
    "    print('\\n')\n",
    "    print('Estimated Landmarks:')\n",
    "    for i in range(len(landmarks)):\n",
    "        print('['+', '.join('%.3f'%l for l in landmarks[i])+']')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SLAM\n",
    "\n",
    "\n",
    "#### Landmark Locations\n",
    "\n",
    "Referring back to the printout of *exact* landmark locations when this data was created, we see values that are very similar to those coordinates, but not quite (since `slam` must account for noise in motion and measurement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call your implementation of slam, passing in the necessary parameters\n",
    "mu = slam(data, N, num_landmarks, world_size, motion_noise, measurement_noise)\n",
    "\n",
    "# print out the resulting landmarks and poses\n",
    "if(mu is not None):\n",
    "    # get the lists of poses and landmarks\n",
    "    # and print them out\n",
    "    poses, landmarks = get_poses_landmarks(mu, N)\n",
    "    print_all(poses, landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the constructed world\n",
    "\n",
    "Finally, using the `display_world` code from the `helpers.py` file we can actually visualize the final position of the robot and the positon of landmarks, created from only motion and measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the helper function\n",
    "from helpers import display_world\n",
    "\n",
    "# Display the final world!\n",
    "\n",
    "# define figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "# check if poses has been created\n",
    "if 'poses' in locals():\n",
    "    # print out the last pose\n",
    "    print('Last pose: ', poses[-1])\n",
    "    # display the last position of the robot *and* the landmark positions\n",
    "    display_world(int(world_size), poses[-1], landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
